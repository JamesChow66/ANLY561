{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This code imports numpy packages and allows us to pass data from python to global javascript\n",
    "objects. It was developed by znah@github\n",
    "'''\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import HTML, Javascript, display\n",
    "\n",
    "def json_numpy_serializer(o):\n",
    "    if isinstance(o, np.ndarray):\n",
    "        return o.tolist()\n",
    "    raise TypeError(\"{} of type {} is not JSON serializable\".format(repr(o), type(o)))\n",
    "\n",
    "def jsglobal(**params):\n",
    "    code = [];\n",
    "    for name, value in params.items():\n",
    "        jsdata = json.dumps(value, default=json_numpy_serializer)\n",
    "        code.append(\"window.{}={};\".format(name, jsdata))\n",
    "    display(Javascript(\"\\n\".join(code)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "// Loading the compiled MathBox bundle.\n",
       "require.config({\n",
       "    baseUrl:'', paths: {mathBox: '../../tree/static/mathbox/build/mathbox-bundle'}\n",
       "    // online compilation\n",
       "    // baseUrl: '', paths: {mathBox: '../static/mathbox/build/mathbox-bundle'}\n",
       "    // online compilation without local library-- remove baseUrl\n",
       "    //paths: {mathBox: '//cdn.rawgit.com/unconed/mathbox/eaeb8e15/build/mathbox-bundle'}\n",
       "});\n",
       "\n",
       "// Minified graphing functions\n",
       "\n",
       "window.with_mathbox=function(element,func){require(['mathBox'],function(){var mathbox=mathBox({plugins:['core','controls','cursor','mathbox'],controls:{klass:THREE.OrbitControls},mathbox:{inspect:!1},element:element[0],loop:{start:!1},});var three=mathbox.three;three.renderer.setClearColor(new THREE.Color(0xFFFFFF),1.0);three.camera.position.set(-1,1,2);three.controls.noKeys=!0;three.element.style.height=\"400px\";three.element.style.width=\"100%\";function isInViewport(element){var rect=element.getBoundingClientRect();var html=document.documentElement;var w=window.innerWidth||html.clientWidth;var h=window.innerHeight||html.clientHeight;return rect.top<h&&rect.left<w&&rect.bottom>0&&rect.right>0}\n",
       "var intervalId=setInterval(function(){if(three.element.offsetParent===null){clearInterval(intervalId);three.destroy();return}\n",
       "var visible=isInViewport(three.canvas);if(three.Loop.running!=visible){visible?three.Loop.start():three.Loop.stop()}},100);func(mathbox);window.dispatchEvent(new Event('resize'))})};window.plotGraph=function(mathbox,f,xlabel='x',ylabel='y',zlabel='f(x,y)',rng=[[-3,3],[-5,5],[-3,3]]){var view=mathbox.cartesian({range:rng,scale:[1,1,1]},{rotation:(t)=>[0,t*0.02,0]}).grid({axes:[1,3]})\n",
       "view.area({id:'yaxis',width:1,height:1,axes:[1,3],expr:function(emit,x,y,i,j){emit(4,0,0);emit(0,0,0)},items:2,channels:3,}).text({font:'Helvetica',style:'bold',width:16,height:5,depth:2,expr:function(emit,i,j,k,time){emit(ylabel)},}).label({color:'#000000',snap:!1,outline:2,size:24,offset:[0,-32],depth:.5,zIndex:1});view.vector({points:'#yaxis',color:0x000000,width:9,start:!0});view.area({id:'xaxis',width:1,height:1,axes:[1,3],expr:function(emit,x,y,i,j){emit(0,0,4);emit(0,0,0)},items:2,channels:3,}).text({font:'Helvetica',style:'bold',width:16,height:5,depth:2,expr:function(emit,i,j,k,time){emit(xlabel)},}).label({color:'#000000',snap:!1,outline:2,size:24,offset:[0,-32],depth:.5,zIndex:1,});view.vector({points:'#xaxis',color:0x000000,width:9,start:!0,});view.area({id:'zaxis',width:1,height:1,axes:[1,3],expr:function(emit,x,y,i,j){emit(0,4,0);emit(0,0,0)},items:2,channels:3,}).text({font:'Helvetica',style:'bold',width:16,height:5,depth:2,expr:function(emit,i,j,k,time){emit(zlabel)},}).label({color:'#000000',snap:!1,outline:2,size:24,offset:[0,-32],depth:.5,zIndex:1,});view.vector({points:'#zaxis',color:0x000000,width:9,start:!0,});var graph=view.area({id:'graph',width:64,height:64,axes:[1,3],expr:function(emit,y,x,i,j){emit(y,f(x,y),x)},items:1,channels:3,});view.surface({shaded:!0,lineX:!0,lineY:!0,points:graph,color:0x0000FF,width:1,});return view};window.addSegment=function(view,p0,p1,col){view.array({width:128,expr:function(emit,i,time){var b=i/128;var a=1-b;emit(a*p0[1]+b*p1[1],a*p0[2]+b*p1[2],a*p0[0]+b*p1[0])},channels:3,});view.line({color:col,width:10,size:2.5,stroke:'dotted',start:!1,end:!1,})};window.addPoint=function(view,p,col,label){view.array({width:4,items:2,channels:3,expr:function(emit,i,t){emit(p[1],p[2],p[0])},}).point({color:col,points:'<',size:15,depth:.5,zBias:50,}).text({font:'Helvetica',style:'bold',width:16,height:5,depth:2,expr:function(emit,i,j,k,time){emit(label)},}).label({color:col,snap:!1,outline:2,size:24,offset:[0,-32],depth:.5,zIndex:1,})};window.addCurve=function(view,ab,x,y,z,col){view.array({width:128,expr:function(emit,i,time){var t=(ab[1]-ab[0])*(i/128)+ab[0];emit(y(t),z(t),x(t))},channels:3,});view.line({color:col,width:20,size:2.5,start:!0,end:!0,})};window.addClosedCurve=function(view,ab,x,y,z,col){view.array({width:128,expr:function(emit,i,time){var t=(ab[1]-ab[0])*(i/128)+ab[0];emit(y(t),z(t),x(t))},channels:3,});view.line({color:col,width:20,size:2.5,start:!1,end:!1,})};window.addSurface=function(view,ab,cd,x,y,z,col,opa){view.matrix({width:64,height:64,expr:function(emit,i,j,time){var p=(ab[1]-ab[0])*(i/64)+ab[0];var q=(cd[1]-cd[0])*(j/64)+cd[0];emit(y(p,q),z(p,q),x(p,q))},items:1,channels:3}).surface({shaded:!0,lineX:!1,lineY:!1,color:col,width:1,opacity:opa})}\n",
       "window.addSequence=function(view,seq,col){var idx=0;var d=new Date();var start=d.getTime();view.array({width:1,expr:function(emit,i,time){var nd=new Date();var now=nd.getTime();if(1000<now-start){idx=idx+1;if(seq.length<=idx){idx=0}\n",
       "start=now}\n",
       "emit(seq[idx][1],seq[idx][2],seq[idx][0])},items:1,channels:3}).point({color:col,points:'<',size:15,depth:.5,zBias:50,})}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "// Loading the compiled MathBox bundle.\n",
    "require.config({\n",
    "    baseUrl:'', paths: {mathBox: '../../tree/static/mathbox/build/mathbox-bundle'}\n",
    "    // online compilation\n",
    "    // baseUrl: '', paths: {mathBox: '../static/mathbox/build/mathbox-bundle'}\n",
    "    // online compilation without local library-- remove baseUrl\n",
    "    //paths: {mathBox: '//cdn.rawgit.com/unconed/mathbox/eaeb8e15/build/mathbox-bundle'}\n",
    "});\n",
    "\n",
    "// Minified graphing functions\n",
    "\n",
    "window.with_mathbox=function(element,func){require(['mathBox'],function(){var mathbox=mathBox({plugins:['core','controls','cursor','mathbox'],controls:{klass:THREE.OrbitControls},mathbox:{inspect:!1},element:element[0],loop:{start:!1},});var three=mathbox.three;three.renderer.setClearColor(new THREE.Color(0xFFFFFF),1.0);three.camera.position.set(-1,1,2);three.controls.noKeys=!0;three.element.style.height=\"400px\";three.element.style.width=\"100%\";function isInViewport(element){var rect=element.getBoundingClientRect();var html=document.documentElement;var w=window.innerWidth||html.clientWidth;var h=window.innerHeight||html.clientHeight;return rect.top<h&&rect.left<w&&rect.bottom>0&&rect.right>0}\n",
    "var intervalId=setInterval(function(){if(three.element.offsetParent===null){clearInterval(intervalId);three.destroy();return}\n",
    "var visible=isInViewport(three.canvas);if(three.Loop.running!=visible){visible?three.Loop.start():three.Loop.stop()}},100);func(mathbox);window.dispatchEvent(new Event('resize'))})};window.plotGraph=function(mathbox,f,xlabel='x',ylabel='y',zlabel='f(x,y)',rng=[[-3,3],[-5,5],[-3,3]]){var view=mathbox.cartesian({range:rng,scale:[1,1,1]},{rotation:(t)=>[0,t*0.02,0]}).grid({axes:[1,3]})\n",
    "view.area({id:'yaxis',width:1,height:1,axes:[1,3],expr:function(emit,x,y,i,j){emit(4,0,0);emit(0,0,0)},items:2,channels:3,}).text({font:'Helvetica',style:'bold',width:16,height:5,depth:2,expr:function(emit,i,j,k,time){emit(ylabel)},}).label({color:'#000000',snap:!1,outline:2,size:24,offset:[0,-32],depth:.5,zIndex:1});view.vector({points:'#yaxis',color:0x000000,width:9,start:!0});view.area({id:'xaxis',width:1,height:1,axes:[1,3],expr:function(emit,x,y,i,j){emit(0,0,4);emit(0,0,0)},items:2,channels:3,}).text({font:'Helvetica',style:'bold',width:16,height:5,depth:2,expr:function(emit,i,j,k,time){emit(xlabel)},}).label({color:'#000000',snap:!1,outline:2,size:24,offset:[0,-32],depth:.5,zIndex:1,});view.vector({points:'#xaxis',color:0x000000,width:9,start:!0,});view.area({id:'zaxis',width:1,height:1,axes:[1,3],expr:function(emit,x,y,i,j){emit(0,4,0);emit(0,0,0)},items:2,channels:3,}).text({font:'Helvetica',style:'bold',width:16,height:5,depth:2,expr:function(emit,i,j,k,time){emit(zlabel)},}).label({color:'#000000',snap:!1,outline:2,size:24,offset:[0,-32],depth:.5,zIndex:1,});view.vector({points:'#zaxis',color:0x000000,width:9,start:!0,});var graph=view.area({id:'graph',width:64,height:64,axes:[1,3],expr:function(emit,y,x,i,j){emit(y,f(x,y),x)},items:1,channels:3,});view.surface({shaded:!0,lineX:!0,lineY:!0,points:graph,color:0x0000FF,width:1,});return view};window.addSegment=function(view,p0,p1,col){view.array({width:128,expr:function(emit,i,time){var b=i/128;var a=1-b;emit(a*p0[1]+b*p1[1],a*p0[2]+b*p1[2],a*p0[0]+b*p1[0])},channels:3,});view.line({color:col,width:10,size:2.5,stroke:'dotted',start:!1,end:!1,})};window.addPoint=function(view,p,col,label){view.array({width:4,items:2,channels:3,expr:function(emit,i,t){emit(p[1],p[2],p[0])},}).point({color:col,points:'<',size:15,depth:.5,zBias:50,}).text({font:'Helvetica',style:'bold',width:16,height:5,depth:2,expr:function(emit,i,j,k,time){emit(label)},}).label({color:col,snap:!1,outline:2,size:24,offset:[0,-32],depth:.5,zIndex:1,})};window.addCurve=function(view,ab,x,y,z,col){view.array({width:128,expr:function(emit,i,time){var t=(ab[1]-ab[0])*(i/128)+ab[0];emit(y(t),z(t),x(t))},channels:3,});view.line({color:col,width:20,size:2.5,start:!0,end:!0,})};window.addClosedCurve=function(view,ab,x,y,z,col){view.array({width:128,expr:function(emit,i,time){var t=(ab[1]-ab[0])*(i/128)+ab[0];emit(y(t),z(t),x(t))},channels:3,});view.line({color:col,width:20,size:2.5,start:!1,end:!1,})};window.addSurface=function(view,ab,cd,x,y,z,col,opa){view.matrix({width:64,height:64,expr:function(emit,i,j,time){var p=(ab[1]-ab[0])*(i/64)+ab[0];var q=(cd[1]-cd[0])*(j/64)+cd[0];emit(y(p,q),z(p,q),x(p,q))},items:1,channels:3}).surface({shaded:!0,lineX:!1,lineY:!1,color:col,width:1,opacity:opa})}\n",
    "window.addSequence=function(view,seq,col){var idx=0;var d=new Date();var start=d.getTime();view.array({width:1,expr:function(emit,i,time){var nd=new Date();var now=nd.getTime();if(1000<now-start){idx=idx+1;if(seq.length<=idx){idx=0}\n",
    "start=now}\n",
    "emit(seq[idx][1],seq[idx][2],seq[idx][0])},items:1,channels:3}).point({color:col,points:'<',size:15,depth:.5,zBias:50,})}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V: Necessary and Sufficient Conditions for Optimality\n",
    "\n",
    "\n",
    "We begin by generalizing the necessary conditions for optimality from 1D. The key is to note that, if ${\\bf x}^\\ast=(x_1^\\ast, x_2^\\ast)$ is a solution to $\\min f({\\bf x})$, then $x_1^\\ast$ is a solution to\n",
    "$$\n",
    "\\min_{x_1} f(x_1, x_2^\\ast)\n",
    "$$\n",
    "and $x_2^\\ast$ is a solution to\n",
    "$$\n",
    "\\min_{x_2} f(x_1^\\ast, x_2). \n",
    "$$\n",
    "Consequently, the necessary conditions for optimality imply that $\\partial_1 f({\\bf x}^\\ast)=\\partial_2 f({\\bf x}^\\ast)=0$, or (in other words) the **gradient of** $f$ **vanishes at** ${\\bf x}^\\ast$:\n",
    "$$\n",
    "\\nabla f({\\bf x}^\\ast) = \\begin{pmatrix}\n",
    "\\partial_1 f({\\bf x}^\\ast)\\\\\n",
    "\\partial_2 f({\\bf x}^\\ast)\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "0\\\\\n",
    "0\n",
    "\\end{pmatrix}={\\bf 0}.\n",
    "$$\n",
    "\n",
    "Now, the **interior** of a set $X\\subset\\mathbb{R}^2$, denoted $\\text{int}(X)$ is the largest open subset of $\\mathbb{R}^2$ in $X$. In particular, ${\\bf x}\\in \\text{int}(X)$ if and only if there is an $\\varepsilon>0$ such that $B({\\bf x}, \\varepsilon)\\subset X$.\n",
    "\n",
    "#### Theorem (Necessary Conditions for Optimality): If $X\\subset\\mathbb{R}^2$, $f\\in C^1(X)$, and ${\\bf x}^\\ast\\in\\text{int}(X)$ is a minimizer of $f$, then $\\nabla f({\\bf x}^\\ast)={\\bf 0}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value at the critical point (2.0, 0.0) is 2.0\n",
      "Value at the critical point (-1.7, 0.0) is 16.9\n",
      "Value at the critical point (-0.3, 0.0) is 22.6\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Example: 8*y**2 + (x-2)**2*((x+2)**2+1) + 2\n",
    "'''\n",
    "\n",
    "f = lambda x, y: 8*y**2 + (x-2)**2*((x+2)**2+1) + 2\n",
    "\n",
    "dfy = lambda x, y: 16*y\n",
    "dfx = lambda x, y: 4*x*(x**2-4) + 2*(x-2)\n",
    "\n",
    "# Note that dfx is 4*x*(x**2-4)+2*(x-2)=4*x**3 - 14*x - 4\n",
    "cx = [4, 0, -14, -4]\n",
    "rootx = np.roots(cx)\n",
    "\n",
    "# So, the critical points must all have y=0, and x must be in root x. Thus,\n",
    "\n",
    "for a in rootx:\n",
    "    print('Value at the critical point (%2.1f, %2.1f) is %2.1f' % (a, 0.0, f(a, 0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points where $\\nabla f({\\bf x})={\\bf 0}$ are called **critical points**. There are several important types of critical points.\n",
    "\n",
    "1. ${\\bf x}$ is a **local minimizer** of $f:X\\rightarrow\\mathbb{R}$ if there is an $\\varepsilon>0$ such that $f({\\bf x})\\leq f({\\bf y})$ for all ${\\bf y}\\in B({\\bf x},\\varepsilon)\\cap X$.\n",
    "2. ${\\bf x}$ is a **local maximizer** of $f:X\\rightarrow\\mathbb{R}$ if there is an $\\varepsilon>0$ such that $f({\\bf x})\\geq f({bf y})$ for all ${\\bf y}\\in B({\\bf x},\\varepsilon)\\cap X$\n",
    "3. ${\\bf x}$ is a **global minimizer** of $f:X\\rightarrow\\mathbb{R}$ if $f({\\bf x})\\leq f({\\bf y})$ for all ${\\bf y}\\in X$. \n",
    "4. ${\\bf x}$ is a **global maximizer** of $f:X\\rightarrow\\mathbb{R}$ if $f({\\bf x})\\geq f({\\bf y})$ for all ${\\bf y}\\in X$. \n",
    "\n",
    "Note that a global minimizer in the interior of a set must also be a local minimizer. Thus, the second derivative test allows us to exclude all local maximizers from our search.\n",
    "\n",
    "#### Theorem (Second Derivative Test): Let $X\\subset\\mathbb{R}^2$ and $f\\in C^2(X)$. If ${\\bf x}^\\ast\\in \\text{int}(X)$ is a global minimizer, then $\\nabla^2 f({\\bf x}^\\ast)$ is positive semidefinite.\n",
    "\n",
    "With a one more condition on $f$, the necessary conditions also become sufficient conditions.\n",
    "\n",
    "#### Theorem (Sufficient Conditions for Optimality): If $X\\subset\\mathbb{R}^2$ is a convex set, $f\\in C^1(X)$ is convex on $X$, and ${\\bf x}^\\ast\\in X$ satisfies $\\nabla f({\\bf x}^\\ast)={\\bf 0}$, then ${\\bf x}^\\ast$ is a minimizer of $f$ on $X$.\n",
    "\n",
    "## Group Questions\n",
    "\n",
    "1. Explain why $(2,0)$ is the minimizer in the above numerical example.\n",
    "2. Find the minimizer of the function $f(x, y)=1 + 2x + y + 2x^2 + xy + 2y^2$.\n",
    "3. Find the minimizer of the function $f(x, y)=(1 - 2x + y)^2 + (2 - x + 2y)^2$.\n",
    "4. Find the minimizer of the function $f(x, y)=\\vert 1-2x +y\\vert + \\vert 2-x + 2y\\vert$.\n",
    "5. Write out and simplify the necessary conditions for optimality given the function $f(x, y)=e^{-(x-1)^2-(y-1)^2} + e^{-(y-2)^2}$.\n",
    "6. Write out and simplify the necessary conditions for optimality given the function $f(x, y)=\\frac{x^4+y^4+1}{(x-1)^2 + (y-2)^2+1}$.\n",
    "7. Find the minimizer of the function $f(x, y) = 1 + 2x^2 + y^2 + 2x^4 + x^2y^2 + 2y^4$.\n",
    "8. Find the minimizer of the function $f(x, y) = (2 + 2x + x^2)(3+y+y^2)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VI: Equality Constrained Minimization\n",
    "\n",
    "In 2D, we have enough room to run into a single equality constraint. For example, consider the program\n",
    "$$\n",
    "\\min 2x^2 + 2xy + 2y^2\\text{ subject to } x^2 + y^2 -1 = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "with_mathbox(element, function(mathbox) {\n",
       "    \n",
       "    var fcn = function(x, y) {\n",
       "        return 2*(x*x + x*y + y*y);\n",
       "    }\n",
       "    \n",
       "    var view = plotGraph(mathbox, fcn);\n",
       "     \n",
       "    addClosedCurve(view,\n",
       "             [0, 6.4],\n",
       "             function(t){return Math.cos(t);},\n",
       "             function(t){return Math.sin(t);},\n",
       "             function(t){return 0;},\n",
       "             0x3090FF\n",
       "            );\n",
       "    \n",
       "    addClosedCurve(view,\n",
       "             [0, 6.4],\n",
       "             function(t){return Math.cos(t);},\n",
       "             function(t){return Math.sin(t);},\n",
       "             function(t){return fcn(Math.cos(t), Math.sin(t));},\n",
       "             0xFF8C00\n",
       "            );\n",
       "})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "with_mathbox(element, function(mathbox) {\n",
    "    \n",
    "    var fcn = function(x, y) {\n",
    "        return 2*(x*x + x*y + y*y);\n",
    "    }\n",
    "    \n",
    "    var view = plotGraph(mathbox, fcn);\n",
    "     \n",
    "    addClosedCurve(view,\n",
    "             [0, 6.4],\n",
    "             function(t){return Math.cos(t);},\n",
    "             function(t){return Math.sin(t);},\n",
    "             function(t){return 0;},\n",
    "             0x3090FF\n",
    "            );\n",
    "    \n",
    "    addClosedCurve(view,\n",
    "             [0, 6.4],\n",
    "             function(t){return Math.cos(t);},\n",
    "             function(t){return Math.sin(t);},\n",
    "             function(t){return fcn(Math.cos(t), Math.sin(t));},\n",
    "             0xFF8C00\n",
    "            );\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2D, having a single equality constraint means that we can attempt to **eliminate** a variable to reduce the problem to a 1D optimization program. That is, we can use the substitutions $x=\\cos(\\theta)$ and $y=\\sin(\\theta)$ to convert the problem to\n",
    "\n",
    "$$\n",
    "\\min_\\theta 2\\cos(\\theta)^2 + 2\\cos(\\theta)\\sin(\\theta)+2\\sin(\\theta)^2\n",
    "$$\n",
    "\n",
    "where the constraint is now implicit. This new 1D program can be solved analytically.\n",
    "\n",
    "With the goal of higher-dimensional generalizations in mind, let's consider this more abstractly. Set $f(x,y)=2x^2+2xy+2y^2$ and $g(x,y)=x^2+y^2-1$. The constraint $g(x,y)=0$ implied a **parameterization** ${\\bf \\varphi}(\\theta) = (\\cos(\\theta),\\sin(\\theta))$ such that\n",
    "\n",
    "$$\n",
    "g({\\bf \\varphi}(\\theta)) = 0.\n",
    "$$\n",
    "\n",
    "Consequently, we could reduce the program to\n",
    "\n",
    "$$\n",
    "\\min_{\\theta\\in[0,2\\pi]} f({\\bf \\varphi}(\\theta))).\n",
    "$$\n",
    "\n",
    "Necessary conditions for optimality in 1D then implied that\n",
    "\n",
    "$$\n",
    "\\frac{d (f\\circ{\\bf \\varphi})}{d\\theta}(\\theta^\\ast)=0\n",
    "$$\n",
    "\n",
    "for the optimal $\\theta$. \n",
    "\n",
    "Now, $\\frac{d (f\\circ{\\bf \\varphi})}{d\\theta}$ obeys a **chain rule** of the form\n",
    "\n",
    "$$\n",
    "\\frac{d (f\\circ{\\bf \\varphi})}{d\\theta}(\\theta) = \\frac{\\partial f}{\\partial x}({\\bf \\varphi}(\\theta)) \\frac{d\\varphi_1}{d\\theta}(\\theta) + \\frac{\\partial f}{\\partial y}({\\bf \\varphi}(\\theta)) \\frac{d\\varphi_2}{d\\theta}(\\theta)\n",
    "$$\n",
    "\n",
    "where $\\varphi_1(\\theta)=\\cos(\\theta)$ and $\\varphi_2(\\theta)=\\sin(\\theta)$. Why is this the case? Well, a rough heuristic is that\n",
    "\n",
    "$$\n",
    "\\varphi(\\theta + \\Delta\\theta)\\approx \\varphi(\\theta) + \\frac{d\\varphi}{d\\theta}(\\theta)\\Delta\\theta = \\begin{pmatrix}\n",
    "\\varphi_1(\\theta)\\\\\n",
    "\\varphi_2(\\theta)\n",
    "\\end{pmatrix} + \\Delta\\theta\\begin{pmatrix}\n",
    "\\varphi_1^\\prime(\\theta)\\\\\n",
    "\\varphi_2^\\prime(\\theta)\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "for very small $\\Delta\\theta$. Letting\n",
    "\n",
    "$$\n",
    "\\varphi^\\prime(\\theta) = \\begin{pmatrix}\n",
    "\\varphi_1^\\prime(\\theta)\\\\\n",
    "\\varphi_2^\\prime(\\theta)\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "\n",
    "we have $\\varphi(\\theta+\\Delta\\theta)\\approx \\varphi(\\theta) + \\Delta\\theta\\varphi^\\prime(\\theta)$.\n",
    "\n",
    "The first order approximation to $f$ at $\\varphi(\\theta)$ is\n",
    "\n",
    "$$\n",
    "f({\\bf x}) \\approx f(\\varphi(\\theta)) + \\nabla f(\\varphi(\\theta))^T ({\\bf x}-\\varphi(\\theta)).\n",
    "$$\n",
    "\n",
    "Plugging in ${\\bf x} = \\varphi(\\theta) +\\Delta\\theta \\varphi^\\prime(\\theta)$, we have\n",
    "\n",
    "$$\n",
    "f(\\varphi(\\theta + \\Delta\\theta))\\approx f(\\varphi(\\theta)+\\Delta\\theta\\varphi^\\prime(\\theta))\\approx f(\\varphi(\\theta))+\\nabla f(\\varphi(\\theta))^T\\varphi^\\prime(\\theta) \\Delta \\theta.\n",
    "$$\n",
    "\n",
    "This is a first order approximation to $f\\circ\\varphi$ at $\\theta$, and it can be rigorously established that this is **the** first order Taylor approximation to $f\\circ\\varphi$ at $\\theta$. Therefore\n",
    "\n",
    "$$\n",
    "(f\\circ\\varphi)^\\prime(\\theta) = \\nabla f(\\varphi(\\theta))^T\\varphi^\\prime(\\theta)= \\frac{\\partial f}{\\partial x}({\\bf \\varphi}(\\theta)) \\frac{d\\varphi_1}{d\\theta}(\\theta) + \\frac{\\partial f}{\\partial y}({\\bf \\varphi}(\\theta)) \\frac{d\\varphi_2}{d\\theta}(\\theta)\n",
    "$$\n",
    "\n",
    "The necessary conditions for optimality are then that $\\nabla f(\\varphi(\\theta^\\ast))^T\\phi^\\prime(\\theta)=0$, and therefore the gradient $\\nabla f(\\varphi(\\theta^\\ast))$ is **orthogonal** or **perpendicular** (${\\bf v},{\\bf w}\\in\\mathbb{R}^2$ are orthogonal if ${\\bf v}^T{\\bf w}=0$) to the tangent $\\varphi^\\prime(\\theta^\\ast)$. On the other hand, we know that\n",
    "\n",
    "$$\n",
    "g(\\varphi(\\theta))=0\n",
    "$$\n",
    "\n",
    "and hence\n",
    "\n",
    "$$\n",
    "0 = \\frac{d(g\\circ\\varphi)}{d\\theta}(\\theta)=\\nabla g(\\varphi(\\theta))^T\\varphi^\\prime(\\theta))\n",
    "$$\n",
    "\n",
    "for all $\\theta$. So, we also know that $\\varphi^\\prime(\\theta^\\ast)$ is also orthogonal to $\\nabla g(\\varphi(\\theta^\\ast))$. Since $\\varphi^\\prime(\\theta^\\ast)\\not={\\bf 0}$, and we are in 2D, it must be the case that $\\nabla f(\\theta^\\ast)$ and $\\nabla g(\\theta^\\ast)$ are parallel, and hence there is a $\\lambda\\in\\mathbb{R}$ such that $\\nabla f(\\theta^\\ast)=\\lambda \\nabla g(\\theta^\\ast)$. This reasoning justifies the theory of **Lagrange multipliers**, which provides necessary conditions for constrained optimization in 2D with a single inequality constraint.\n",
    "\n",
    "#### Theorem (Lagrange Multipliers): If $f,g \\in C^1(\\mathbb{R}^2)$ and ${\\bf x}^\\ast$ is a minimizer of $f$ subject to  the constraint $g({\\bf x}^\\ast)=0$ satisfying $\\nabla g({\\bf x}^\\ast)\\not={\\bf 0}$, then there exists a $\\lambda\\in\\mathbb{R}$ such that $\\nabla f({\\bf x}^\\ast)=\\lambda\\nabla g({\\bf x}^\\ast)$.\n",
    "\n",
    "Geometrically, we can think of $-\\nabla f$ pointing in the direction of greatest local decrease of the function $f$, and the tangent to a parameterization of $g({\\bf x})=0$ around a solution must be orthogonal to this, or we could locally decrease the function further. \n",
    "\n",
    "\n",
    "## Group Questions\n",
    "\n",
    "1. Use Lagrange multipliers to solve $\\displaystyle \\min 2x^2+2xy+2y^2$ subject to $x^2+y^2=1$.\n",
    "2. Use Lagrange multipliers to solve $\\displaystyle \\min 2x - y$ subject to $x^2+y^2=1$.\n",
    "3. Use Lagrange multipliers to solve $\\displaystyle \\min 2x - y$ subject to $xy=1$.\n",
    "4. Use Lagrange multipliers to solve $\\displaystyle \\min 2x^2+2xy+2y^2$ subject to $xy=1$.\n",
    "5. Find an implicit parameterization of the constraint $x^2 + xy + y^2 + x = 2$ at $(x,y)=(1, -1)$\n",
    "6. Let $g(x,y)=x^3 + xy + y^2 + x - 2$ and suppose $\\gamma:\\mathbb{R}\\rightarrow\\mathbb{R}^2$ satisfies $g\\in C^1(\\mathbb{R};\\mathbb{R}^2)$, $g(\\gamma(t))=0$ for all $t\\in\\mathbb{R}$, and $\\gamma(0)=(1, -1)$. Explain why $\\gamma^\\prime(0)$ is parallel to $(1, 3)$.\n",
    "7. Find an implicit parameterization of the constraint $x^3 + xy + y^2 + x - 2$ at $(x, y)=(1, -1)$.\n",
    "8. Find a function $g\\in C^1(\\mathbb{R}^2)$ such $g(\\gamma(t))=0$ for all $t\\in\\mathbb{R}$, and where $\\gamma(t) = (1+\\sin(t)+\\cos(t) + \\cos^2(t), t)$, and $g(x, y)\\not = 0$ if there is no $t\\in\\mathbb{R}$ such that $\\gamma(t)=(x,y)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VI: Iterative methods\n",
    "\n",
    "When the analytic techniques fail, we fall back on iterative methods. The goal is to produce a sequence ${\\bf x}^{(0)}, {\\bf x}^{(1)}, {\\bf x}^{(2)},\\ldots$ iteratively by choosing ${\\bf x}^{(k+1)}$ so that\n",
    "\n",
    "1. ${\\bf x}^{(k+1)}$ only depends on ${\\bf x}^{(0)},{\\bf x}^{(1)}, {\\bf x}^{(2)},\\ldots,{\\bf x}^{(k)}$. Ideally, ${\\bf x}^{(k+1)}$ only depends on ${\\bf x}^{(k)}$.\n",
    "2. The algorithm uses as few evaluations of $f$, $\\nabla f$, or $\\nabla^2 f$ as possible.\n",
    "3. The sequence of iterates ideally satisfies $f({\\bf x}^{(0)}) > f({\\bf x}^{(1)}) > f({\\bf x}^{(2)}) >\\cdots$\n",
    "4. The sequence ${\\bf x}^{(0)}, {\\bf x}^{(1)}, {\\bf x}^{(2)},\\ldots$ converges to ${\\bf x}^\\ast$, which is at least a local minimum of $f$. Moreover, the convergence should not be too slow.\n",
    "\n",
    "There is already a large amount of room to move in 2D, so iterative procedures generally proceed by considering a sequence of **line searches**. That is, for each iterate ${\\bf x}^{(k)}$, we will choose a **search direction** $\\Delta{\\bf x}^{(k+1)}\\in\\mathbb{R}^2$, pick a $t^{(k+1)}>0$, and then set\n",
    "\n",
    "$$\n",
    "{\\bf x}^{(k+1)} = {\\bf x}^{(k)} + t^{(k+1)}\\Delta{\\bf x}^{(k+1)}.\n",
    "$$\n",
    "\n",
    "This is called a line search because the set\n",
    "$$\n",
    "\\{{\\bf x}^{(k)} + t\\Delta{\\bf x}^{(k+1)}\\in\\mathbb{R}^2:t\\in\\mathbb{R}\\}\n",
    "$$ \n",
    "is a line in $\\mathbb{R}^2$. \n",
    "\n",
    "How do we choose $\\Delta{\\bf x}^{(k+1)}$ and $t^{(k+1)}$? We will address the choice of $\\Delta{\\bf x}^{(k+1)}$ soon, but we note that the choice of $\\Delta{\\bf x}^{(k+1)}$ suggests that we then choose $t^{(k+1)}$ to approximately solve the 1D optimization program \n",
    "$$\n",
    "\\min_{t\\in\\mathbb{R}} f({\\bf x}^{(k)} + t\\Delta{\\bf x}^{(k+1)}).\n",
    "$$\n",
    "Now, one way to do this is to let $t^{(k+1)}$ be a solution to this program. This is the **optimal step size**. In practice this is unnecessary since we will use a lot of evaluations to optimize over a single line when there are an infinite number to ultimately consider. Consequently, we will generally choose $t^{(k+1)}$ by performing **a single step of backtracking**. \n",
    "\n",
    "In order to ensure that that $f({\\bf x}^{(k+1)})\\leq f({\\bf x}^{(k)})$ using the step size from backtracking, we must choose $\\Delta x^{(k+1)}$ so that the Armijo condition is eventually satisfied. That is, there needs to be an $N$ such that\n",
    "$$\n",
    "f({\\bf x}^{(k)} + \\beta^n\\Delta{\\bf x}^{(k+1)})\\leq f({\\bf x}^{(k)}) + \\alpha\\beta^n\\nabla f({\\bf x}^{(k)})^T\\Delta{\\bf x}^{(k+1)}< f({\\bf x}^{(k)})\n",
    "$$\n",
    "for all $n\\geq N$, and where $\\alpha,\\beta\\in(0,1)$ are the backtracking parameters.\n",
    "\n",
    "In 1D, we showed that the steepest descent $\\Delta x^{(k+1)}=-f^\\prime(x^{(k)})$ satisfied this property. The generalization of this to 2D is **gradient descent**:\n",
    "$$\n",
    "\\Delta {\\bf x}^{(k+1)} = -\\nabla f({\\bf x}^{(k)}).\n",
    "$$\n",
    "One good reason for this choice is that, for any $t>0$, the solution to\n",
    "$$\n",
    "\\min_{\\Delta {\\bf x}\\in\\mathbb{R}^2} f({\\bf x}^{(0)}) + t\\nabla f({\\bf x}^{(0)})^T\\Delta{\\bf x}\\text{ subject to }\\Vert\\Delta {\\bf x}\\Vert=1\n",
    "$$\n",
    "is given by $\\Delta{\\bf x}^\\ast = -\\frac{1}{\\Vert \\nabla f({\\bf x}^{(0)})\\Vert} \\nabla f({\\bf x}^{(0)})$. Since $f({\\bf x}^{(0)}) + t\\nabla f({\\bf x}^{(0)})^T\\Delta{\\bf x}$ is the first order approximation to $f({\\bf x}^{(0)}+t\\Delta{\\bf x})$, we conclude that $-\\nabla f({\\bf x}^{(0)})$ points in the direction of the largest local decrease at ${\\bf x}^{(0)}$.\n",
    "\n",
    "Let's see an example of backtracking using steepest descent directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def backtracking(x0, dx, f, df0, alpha=0.2, beta=0.8, verbose=False):\n",
    "    '''\n",
    "    Backtracking for general functions with illustrations\n",
    "    :param x0: Previous point from backtracking, or initial guess\n",
    "    :param dx: Incremental factor for updating x0\n",
    "    :param f: Objective function\n",
    "    :param df0: Gradient of f at x0\n",
    "    :param alpha: Sloping factor of stopping criterion\n",
    "    :param beta: \"Agressiveness\" parameter for backtracking steps\n",
    "    :param verbose: Boolean for providing plots and data\n",
    "    :return: x1, the next iterate in backtracking\n",
    "    '''\n",
    "\n",
    "    # Note that the definition below requires that dx and df0 have the same shape\n",
    "    delta = alpha * np.sum(dx * df0) # A general, but memory intensive inner product\n",
    "    \n",
    "    t = 1 # Initialize t=beta^0\n",
    "    f0 = f(x0) # Evaluate for future use\n",
    "    x = x0 + dx # Initialize x_{0, inner}\n",
    "    fx = f(x)\n",
    "    \n",
    "    if verbose:\n",
    "        n=0\n",
    "        xs = [x]\n",
    "        fs = [fx]\n",
    "        ts = [1] * 3\n",
    "    \n",
    "    while (not np.isfinite(fx)) or f0 + delta * t < fx:\n",
    "        t = beta * t\n",
    "        x = x0 + t * dx\n",
    "        fx = f(x)\n",
    "    ###################################### \n",
    "    \n",
    "        if verbose:\n",
    "            n += 1\n",
    "            xs.append(x)\n",
    "            fs.append(fx)\n",
    "            ts.append(t)\n",
    "            ts.pop(0)\n",
    "            \n",
    "    if verbose:\n",
    "        # Display the function along the line search direction as a function of t\n",
    "        s = np.linspace(-0.1*ts[-1], 1.1*ts[0], 100)\n",
    "        xi = [0, 1.1*ts[0]]\n",
    "        fxi = [f0, f0 + 1.1*ts[0]*delta]   \n",
    "        y = np.zeros(len(s))\n",
    "        \n",
    "        for i in range(len(s)):\n",
    "            y[i] = f(x0 + s[i]*dx) # Slow for vectorized functions\n",
    "\n",
    "        plt.figure('Backtracking illustration')\n",
    "        arm, =plt.plot(xi, fxi, '--', label='Armijo Criterion')\n",
    "        fcn, =plt.plot(s, y, label='Objective Function')\n",
    "        plt.plot([s[0], s[-1]], [0, 0], 'k--')\n",
    "        pts =plt.scatter(ts, [0 for p in ts], label='Backtracking points for n=%d, %d, %d' % (n, n+1, n+2))\n",
    "        plt.scatter(ts, [f(x0 + q*dx) for q in ts] , label='Backtracking values for n=%d, %d, %d' % (n, n+1, n+2))\n",
    "        init =plt.scatter([0], [f0], color='black', label='Initial point')\n",
    "        plt.xlabel('$t$')\n",
    "        plt.ylabel('$f(x^{(k)}+t\\Delta x^{(k+1)})$')\n",
    "        plt.legend(handles=[arm, fcn, pts, init])\n",
    "        plt.show()\n",
    "        \n",
    "        return x, xs, fs\n",
    "    \n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def procPointValue(p, f):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    for i in range(len(f)):\n",
    "        x.append(p[i][0])\n",
    "        y.append(p[i][1])\n",
    "        z.append(f[i])\n",
    "    \n",
    "    return np.vstack([x, y, z]).T\n",
    "        \n",
    "\n",
    "fun = lambda x: (2 + 8*x[1]*x[1] + (x[0]-2)**2 * ((x[0]+2)**2+1))/20\n",
    "dfun = lambda x: np.array([((x[0]-2)*((x[0]+2)**2+1) + (x[0]-2)**2 * (x[0]+2)) / 10, 4*x[1]/5])\n",
    "\n",
    "x0 = np.array([3, 3])\n",
    "dx = -dfun(x0)\n",
    "\n",
    "alpha = 0.8\n",
    "beta = 0.8\n",
    "\n",
    "x1, xs1, fs1 = backtracking(x0, dx, fun, dfun(x0), alpha=alpha, beta=beta, verbose=True)\n",
    "x2, xs2, fs2 = backtracking(x1, -dfun(x1), fun, dfun(x1), alpha=alpha, beta=beta, verbose=True)\n",
    "x3, xs3, fs3 = backtracking(x2, -dfun(x2), fun, dfun(x2), alpha=alpha, beta=beta, verbose=True)\n",
    "\n",
    "bt1 = procPointValue(xs1, fs1)\n",
    "bt1pts = procPointValue(xs1, [0]*len(fs1))\n",
    "jsglobal(BT1=bt1)\n",
    "jsglobal(BT1PTS=bt1pts)\n",
    "\n",
    "bt2 = procPointValue(xs2, fs2)\n",
    "bt2pts = procPointValue(xs2, [0]*len(fs2))\n",
    "jsglobal(BT2=bt2)\n",
    "jsglobal(BT2PTS=bt2pts)\n",
    "\n",
    "bt3 = procPointValue(xs3, fs3)\n",
    "bt3pts = procPointValue(xs3, [0]*len(fs3))\n",
    "jsglobal(BT3=bt3)\n",
    "jsglobal(BT3PTS=bt3pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "\n",
    "with_mathbox(element, function(mathbox) {\n",
    "    \n",
    "    var fcn = function(x, y) {\n",
    "        return (2 + 8*y*y + Math.pow(x-2,2)*(Math.pow(x+2,2)+1))/20;\n",
    "    }\n",
    "    \n",
    "    var dfcnx = function(x, y) {\n",
    "        return ((x-2)*(Math.pow(x+2,2)+1) + Math.pow(x-2,2)*(x+2))/10;\n",
    "    }\n",
    "    \n",
    "    var dfcny = function(x, y) {\n",
    "        return 4*y/5;\n",
    "    }\n",
    "    \n",
    "    var pt = [3, 3];\n",
    "    var f0 = fcn(pt[0], pt[1]);\n",
    "    var dx = [-dfcnx(pt[0], pt[1]), -dfcny(pt[0], pt[1])];\n",
    "    var delta = -0.8 * (dx[0]*dx[0] + dx[1]*dx[1]);\n",
    "    \n",
    "    var view = plotGraph(mathbox, fcn);\n",
    "    addPoint(view, [3, 3, 0], 0x3090FF, '(3,3)');\n",
    "    addPoint(view, [3, 3, 5], 0xFF9030, '(3,3,5)');\n",
    "    addSequence(view, BT1PTS, 0x000000);\n",
    "    addSequence(view, BT1, 0xFF8C00);\n",
    "    addSegment(view, [pt[0], pt[1], 0], [pt[0]+dx[0], pt[1]+dx[1], 0], 0x00000);\n",
    "    addSegment(view, [pt[0], pt[1], f0], [pt[0]+dx[0], pt[1]+dx[1], f0 + delta], 0xFF8C00);\n",
    "    addCurve(view,\n",
    "             [-0.1, 2.1],\n",
    "             function(t){return pt[0] + t*dx[0];},\n",
    "             function(t){return pt[1] + t*dx[1];},\n",
    "             function(t){return fcn(pt[0] + t*dx[0], pt[1] + t*dx[1]);},\n",
    "             0xFF4500\n",
    "            );\n",
    "    \n",
    "    \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "\n",
    "with_mathbox(element, function(mathbox) {\n",
    "    \n",
    "    var fcn = function(x, y) {\n",
    "        return (2 + 8*y*y + Math.pow(x-2,2)*(Math.pow(x+2,2)+1))/20;\n",
    "    }\n",
    "    \n",
    "    var dfcnx = function(x, y) {\n",
    "        return ((x-2)*(Math.pow(x+2,2)+1) + Math.pow(x-2,2)*(x+2))/10;\n",
    "    }\n",
    "    \n",
    "    var dfcny = function(x, y) {\n",
    "        return 4*y/5;\n",
    "    }\n",
    "    \n",
    "    var pt = [BT1PTS[BT1PTS.length-1][0], BT1PTS[BT1PTS.length-1][1]];\n",
    "    var f0 = fcn(pt[0], pt[1]);\n",
    "    var dx = [-dfcnx(pt[0], pt[1]), -dfcny(pt[0], pt[1])];\n",
    "    var delta = -0.8 * (dx[0]*dx[0] + dx[1]*dx[1]);\n",
    "    \n",
    "    var view = plotGraph(mathbox, fcn);\n",
    "    addPoint(view, [pt[0], pt[1], 0], 0x3090FF, '(' + pt[0].toFixed(2) + ',' + pt[1].toFixed(2) + ')');\n",
    "    addPoint(view, [pt[0], pt[1], f0], 0xFF9030, '(' + pt[0].toFixed(2) + ',' + pt[1].toFixed(2) + ',' + f0.toFixed(2) + ')');\n",
    "    addSequence(view, BT2PTS, 0x000000);\n",
    "    addSequence(view, BT2, 0xFF8C00);\n",
    "    addSegment(view, [pt[0], pt[1], 0], [pt[0]+dx[0], pt[1]+dx[1], 0], 0x00000);\n",
    "    addSegment(view, [pt[0], pt[1], f0], [pt[0]+dx[0], pt[1]+dx[1], f0 + delta], 0xFF8C00);\n",
    "    addCurve(view,\n",
    "             [-0.1, 2.1],\n",
    "             function(t){return pt[0] + t*dx[0];},\n",
    "             function(t){return pt[1] + t*dx[1];},\n",
    "             function(t){return fcn(pt[0] + t*dx[0], pt[1] + t*dx[1]);},\n",
    "             0xFF4500\n",
    "            );\n",
    "    \n",
    "    \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "\n",
    "with_mathbox(element, function(mathbox) {\n",
    "    \n",
    "    var fcn = function(x, y) {\n",
    "        return (2 + 8*y*y + Math.pow(x-2,2)*(Math.pow(x+2,2)+1))/20;\n",
    "    }\n",
    "    \n",
    "    var dfcnx = function(x, y) {\n",
    "        return ((x-2)*(Math.pow(x+2,2)+1) + Math.pow(x-2,2)*(x+2))/10;\n",
    "    }\n",
    "    \n",
    "    var dfcny = function(x, y) {\n",
    "        return 4*y/5;\n",
    "    }\n",
    "    \n",
    "    var pt = [BT2PTS[BT2PTS.length-1][0], BT2PTS[BT2PTS.length-1][1]];\n",
    "    var f0 = fcn(pt[0], pt[1]);\n",
    "    var dx = [-dfcnx(pt[0], pt[1]), -dfcny(pt[0], pt[1])];\n",
    "    var delta = -0.8 * (dx[0]*dx[0] + dx[1]*dx[1]);\n",
    "    \n",
    "    var view = plotGraph(mathbox, fcn);\n",
    "    addPoint(view, [pt[0], pt[1], 0], 0x3090FF, '(' + pt[0].toFixed(2) + ',' + pt[1].toFixed(2) + ')');\n",
    "    addPoint(view, [pt[0], pt[1], f0], 0xFF9030, '(' + pt[0].toFixed(2) + ',' + pt[1].toFixed(2) + ',' + f0.toFixed(2) + ')');\n",
    "    addSequence(view, BT3PTS, 0x000000);\n",
    "    addSequence(view, BT3, 0xFF8C00);\n",
    "    addSegment(view, [pt[0], pt[1], 0], [pt[0]+dx[0], pt[1]+dx[1], 0], 0x00000);\n",
    "    addSegment(view, [pt[0], pt[1], f0], [pt[0]+dx[0], pt[1]+dx[1], f0 + delta], 0xFF8C00);\n",
    "    addCurve(view,\n",
    "             [-0.1, 2.1],\n",
    "             function(t){return pt[0] + t*dx[0];},\n",
    "             function(t){return pt[1] + t*dx[1];},\n",
    "             function(t){return fcn(pt[0] + t*dx[0], pt[1] + t*dx[1]);},\n",
    "             0xFF4500\n",
    "            );\n",
    "    \n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can also use a constant step size for gradient descent. This approximates a continuous **gradient flow**. Now, our previous approximation theory required a bound on $f^{\\prime\\prime}$, but the analgous $\\nabla^2 f$ is a matrix. To obtain a similar theory, we introduce the **spectral norm** or **operator norm** of a 2 by 2 matrix $A$:\n",
    "$$\n",
    "\\Vert A \\Vert = \\min_{\\Vert {\\bf u}\\Vert=1} \\Vert A u\\Vert.\n",
    "$$\n",
    "\n",
    "We have the following convergence rate guarantee, which is the same as in the 1D case:\n",
    "\n",
    "#### Theorem: Suppose $f\\in C^2(\\mathbb{R}^2)$ is convex and also that there is an $M>0$ such that $ \\Vert \\nabla^2 f({\\bf x})\\Vert\\leq M$ for all ${\\bf x}\\in\\mathbb{R}^2$. If ${\\bf x}^{(0)}\\in\\mathbb{R}$ and ${\\bf x}^{(k)}$ are the iterates obtained from successively applying backtracking with gradient descent, then there is a constant $C>0$ such that\n",
    "$$\n",
    "f({\\bf x}^{(k)})-f({\\bf x}^\\ast) \\leq \\frac{C}{k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%javascript \n",
    "\n",
    "with_mathbox(element, function(mathbox) {\n",
    "    \n",
    "    var fcn = function(x, y) {\n",
    "        return (2 + 8*y*y + Math.pow(x-2,2)*(Math.pow(x+2,2)+1))/20;\n",
    "    }\n",
    "    \n",
    "    var dfcnx = function(x, y) {\n",
    "        return ((x-2)*(Math.pow(x+2,2)+1) + Math.pow(x-2,2)*(x+2))/10;\n",
    "    }\n",
    "    \n",
    "    var dfcny = function(x, y) {\n",
    "        return 4*y/5;\n",
    "    }\n",
    "    \n",
    "    var d = new Date();\n",
    "    var start = d.getTime();\n",
    "    var xk = -3*(2*Math.random()-1);\n",
    "    var yk = 3;\n",
    "    var step = 0.01\n",
    "\n",
    "    var view = plotGraph(mathbox, fcn);\n",
    "    \n",
    "    view.area({\n",
    "      id: 'gradient flow',\n",
    "      width: 16,\n",
    "      height: 16,\n",
    "      axes: [1, 3],\n",
    "      expr: function (emit, x, y, i, j) {\n",
    "          emit(y-0.1*dfcny(x, y),0,x-0.1*dfcnx(x, y)); // End of Arrow\n",
    "          emit(y,0,x); // Beginning of Arrow\n",
    "      },\n",
    "      items: 2,\n",
    "      channels: 3,\n",
    "    }).vector({\n",
    "      color: 0x00FF00,\n",
    "      width: 5,\n",
    "      start: true,\n",
    "    });\n",
    "\n",
    "    \n",
    "    view.array({width: 4,\n",
    "                items: 2,\n",
    "                channels: 3,\n",
    "                expr: function (emit, i, t) {\n",
    "                    var di = new Date();\n",
    "                    var now = di.getTime();\n",
    "                    if (di - start < 6000) {\n",
    "                        var grad = [dfcnx(xk, yk), dfcny(xk, yk)];\n",
    "                        xk = xk - step * grad[0];\n",
    "                        yk = yk - step * grad[1];\n",
    "                    } else {\n",
    "                        d = new Date();\n",
    "                        start = d.getTime();\n",
    "                        xk = -3*(2*Math.random()-1);\n",
    "                        yk = 3;\n",
    "                    }\n",
    "                    emit(yk,0,xk);\n",
    "                },\n",
    "               })\n",
    "        .point({color:  0x3090FF,\n",
    "                points: '<',\n",
    "                size: 15,\n",
    "                depth: .5,\n",
    "                zBias: 50\n",
    "               })\n",
    "        .text({font: 'Helvetica',\n",
    "               style: 'bold',\n",
    "               width:  16,\n",
    "               height: 5,\n",
    "               depth:  2,\n",
    "               expr: function (emit, i, j, k, time) {\n",
    "                   emit('(x(k), y(k))');\n",
    "               },\n",
    "              })\n",
    "        .label({color: 0x3090FF,\n",
    "                snap: false,\n",
    "                outline: 2,\n",
    "                size: 24,\n",
    "                offset: [0, -32],\n",
    "                depth: .5,\n",
    "                zIndex: 1,\n",
    "               });\n",
    "    \n",
    "    view.array({width: 4,\n",
    "                items: 2,\n",
    "                channels: 3,\n",
    "                expr: function (emit, i, t) {\n",
    "                    emit(yk, fcn(xk,yk), xk);\n",
    "                },\n",
    "               })\n",
    "        .point({color:  0xFF9030,\n",
    "                points: '<',\n",
    "                size: 15,\n",
    "                depth: .5,\n",
    "                zBias: 50\n",
    "               })\n",
    "        .text({font: 'Helvetica',\n",
    "               style: 'bold',\n",
    "               width:  16,\n",
    "               height: 5,\n",
    "               depth:  2,\n",
    "               expr: function (emit, i, j, k, time) {\n",
    "                   emit('(x(k), y(k), f(x(k), y(k)))');\n",
    "               },\n",
    "              })\n",
    "        .label({color: 0xFF9030,\n",
    "                snap: false,\n",
    "                outline: 2,\n",
    "                size: 24,\n",
    "                offset: [0, -32],\n",
    "                depth: .5,\n",
    "                zIndex: 1,\n",
    "               });\n",
    "    \n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using accelerated backtracking, we also have a nearly optimal rate of convergence:\n",
    "\n",
    "#### Theorem: Suppose $f\\in C^2(\\mathbb{R}^2)$ is convex and also that there is an $M>0$ such that $\\Vert \\nabla^2 f({\\bf x})\\Vert\\leq M$ for all $x\\in\\mathbb{R}$. Then, for the sequence ${\\bf x}^{(1)}, {\\bf x}^{(2)}, {\\bf x}^{(3)},\\ldots$ produced by accelerated backtracking with gradient descent directions, there is a constant $C>0$ such that\n",
    "$$\n",
    "f({\\bf x}^{(k)})-f({\\bf x}^\\ast) \\leq \\frac{C}{k^2}.\n",
    "$$\n",
    "\n",
    "Finally, for sufficiently structured programs we can ensure linear convergence of the iterates to a solution.\n",
    "\n",
    "#### Theorem (Linear Convergence of Gradient Descent): Suppose $f\\in C^2(\\mathbb{R}^2)$, $\\nabla f({\\bf x}^\\ast)=0$, and there is a constant $c>0$ such that ${\\bf u}^T\\nabla f(x){\\bf u}\\geq c$ for all ${\\bf x},{\\bf u}\\in\\mathbb{R}^2$ with $\\Vert {\\bf u}\\Vert=1$. Then there is a $\\gamma\\in(0,1)$ such that gradient descent iterates initialized with any ${\\bf x}^{(0)}$ satisfy  $\\Vert {\\bf x}^{(k+1)} - {\\bf x}^\\ast\\Vert \\leq \\gamma \\Vert {\\bf x}^{(k)}-{\\bf x}^\\ast\\Vert^2$ for all $k\\geq 0$. \n",
    "\n",
    "## Newton Search Directions\n",
    "\n",
    "The generalization of the Newton's direction in $\\mathbb{R}^2$ is\n",
    "\n",
    "$$\n",
    "\\Delta {\\bf x}^{(k+1)} = -\\left(\\nabla^2 f({\\bf x}^{(k)})\\right)^{-1} \\nabla f({\\bf x}^{(k)}) \n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{pmatrix}^{-1} = \\frac{1}{ad-bc} \\begin{pmatrix}\n",
    "d & -b\\\\\n",
    "-c & a\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "is the **inverse matrix** for any matrix with non-zero determinant. This formula is derived by finding the critical point of the second order Taylor approximation at ${\\bf x}^{(k)}$. The gradient of\n",
    "\n",
    "$$\n",
    "p({\\bf x}) = f({\\bf x})^{(k)}) + \\nabla f({\\bf x})^{(k)})^T({\\bf x}-{\\bf x}^{(k)}) + \\frac{1}{2}({\\bf x}-{\\bf x}^{(k)})^T\\nabla^2 f({\\bf x})^{(k)})({\\bf x}-{\\bf x}^{(k)})\n",
    "$$\n",
    "is\n",
    "$$\n",
    "\\nabla p({\\bf x}) = \\nabla f({\\bf x}^{(k)}) + \\nabla^2 f({\\bf x}^{(k)})({\\bf x}-{\\bf x}^{(k)}).\n",
    "$$\n",
    "Setting the above to ${\\bf 0}$ and assuming that $\\nabla^2f({\\bf x}^{(k)})$ is invertible, we then have\n",
    "$$\n",
    "{\\bf x}^{(k+1)}={\\bf x}^{(k)} - \\left(\\nabla^2 f({\\bf x}^{(k)})\\right)^{-1}\\nabla f({\\bf x}^{(k)}).\n",
    "$$\n",
    "\n",
    "#### Theorem (Quadratic Convergence of Newton's Method): Suppose $f\\in C^3(\\mathbb{R}^2)$, $\\nabla f({\\bf x}^\\ast)=0$, there is a constant $c>0$ such that ${\\bf u}^T\\nabla f(x){\\bf u}\\geq c$ for all ${\\bf x},{\\bf u}\\in\\mathbb{R}^2$ with $\\Vert {\\bf u}\\Vert=1$, and there is a constant $K>0$ such that $\\vert \\partial_{i, j, k}f(x)\\vert \\leq K$ for all $x\\in\\mathbb{R}$ and all $i, j, k\\in\\{1, 2\\}$. If ${\\bf x}^{(0)}$ satisfies $\\Vert {\\bf x}^{(0)}-{\\bf x}^\\ast\\vert\\leq \\frac{2c}{3k}$, then the Newton iterates initialized with ${\\bf x}^{(0)}$ satisfy $\\Vert {\\bf x}^{(k)}-{\\bf x}^\\ast\\Vert\\leq \\frac{2c}{3K}$ and $\\Vert {\\bf x}^{(k+1)} - {\\bf x}^\\ast\\Vert \\leq \\frac{3K}{2c} \\Vert {\\bf x}^{(k)}-{\\bf x}^\\ast\\Vert^2$ for all $k\\geq 0$. \n",
    "\n",
    "The **quadratic convergence** here is also known as **doubly exponential convergence** since it implies \n",
    "$$\n",
    "\\Vert {\\bf x}^{(k)}-{\\bf x}^\\ast\\Vert \\leq \\gamma^{2^k-1}\\Vert {\\bf x}^{(0)}-{\\bf x}^\\ast\\Vert\n",
    "$$\n",
    "for some $\\gamma\\in(0,1)$. However, convergence in this theorem is contingent on the fact that $\\Vert {\\bf x}^{(0)}-{\\bf x}^\\ast\\Vert < \\frac{2c}{3K}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%javascript \n",
    "\n",
    "with_mathbox(element, function(mathbox) {\n",
    "    \n",
    "    var fcn = function(x, y) {\n",
    "        return (2 + 8*y*y + Math.pow(x-2,2)*(Math.pow(x+2,2)+1))/20;\n",
    "    };\n",
    "    \n",
    "    var dfcnx = function(x, y) {\n",
    "        return ((x-2)*(Math.pow(x+2,2)+1) + Math.pow(x-2,2)*(x+2))/10;\n",
    "    };\n",
    "    \n",
    "    var dfcny = function(x, y) {\n",
    "        return 4*y/5;\n",
    "    };\n",
    "    \n",
    "    var d2fcn = function(x, y) {\n",
    "        return [[(Math.pow(x+2,2) + 1 + 4*(x*x-1) + Math.pow(x-2,2))/10,0], [0, 0.8]];\n",
    "    };\n",
    "    \n",
    "    var nStep = function(x, y) {\n",
    "        var H11=(Math.pow(x+2,2) + 1 + 4*(x*x-1) + Math.pow(x-2,2))/10;\n",
    "        var H22=0.8;\n",
    "        return [dfcnx(x,y)/H11, dfcny(x,y)/H22];\n",
    "    };\n",
    "    \n",
    "    var d = new Date();\n",
    "    var start = d.getTime();\n",
    "    var xk = -3*(2*Math.random()-1);\n",
    "    var yk = 3;\n",
    "    var step = 0.01\n",
    "\n",
    "    var view = plotGraph(mathbox, fcn);\n",
    "    \n",
    "    view.area({\n",
    "      id: 'Newton flow',\n",
    "      width: 16,\n",
    "      height: 16,\n",
    "      axes: [1, 3],\n",
    "      expr: function (emit, x, y, i, j) {\n",
    "          var nstep=nStep(x, y);\n",
    "          emit(y-0.1*nstep[1], 0, x-0.1*nstep[0]); // End of Arrow\n",
    "          emit(y, 0, x); // Beginning of Arrow\n",
    "      },\n",
    "      items: 2,\n",
    "      channels: 3,\n",
    "    }).vector({\n",
    "      color: 0x00FF00,\n",
    "      width: 5,\n",
    "      start: true,\n",
    "    });\n",
    "\n",
    "    \n",
    "    view.array({width: 4,\n",
    "                items: 2,\n",
    "                channels: 3,\n",
    "                expr: function (emit, i, t) {\n",
    "                    var di = new Date();\n",
    "                    var now = di.getTime();\n",
    "                    if (di - start < 6000) {\n",
    "                        var nstep = nStep(xk, yk);\n",
    "                        xk = xk - step * nstep[0];\n",
    "                        yk = yk - step * nstep[1];\n",
    "                    } else {\n",
    "                        d = new Date();\n",
    "                        start = d.getTime();\n",
    "                        xk = -3*(2*Math.random()-1);\n",
    "                        yk = 3;\n",
    "                    }\n",
    "                    emit(yk, 0, xk);\n",
    "                },\n",
    "               })\n",
    "        .point({color:  0x3090FF,\n",
    "                points: '<',\n",
    "                size: 15,\n",
    "                depth: .5,\n",
    "                zBias: 50\n",
    "               })\n",
    "        .text({font: 'Helvetica',\n",
    "               style: 'bold',\n",
    "               width:  16,\n",
    "               height: 5,\n",
    "               depth:  2,\n",
    "               expr: function (emit, i, j, k, time) {\n",
    "                   emit('(x(k), y(k))');\n",
    "               },\n",
    "              })\n",
    "        .label({color: 0x3090FF,\n",
    "                snap: false,\n",
    "                outline: 2,\n",
    "                size: 24,\n",
    "                offset: [0, -32],\n",
    "                depth: .5,\n",
    "                zIndex: 1,\n",
    "               });\n",
    "    \n",
    "    view.array({width: 4,\n",
    "                items: 2,\n",
    "                channels: 3,\n",
    "                expr: function (emit, i, t) {\n",
    "                    emit(yk, fcn(xk,yk), xk);\n",
    "                },\n",
    "               })\n",
    "        .point({color:  0xFF9030,\n",
    "                points: '<',\n",
    "                size: 15,\n",
    "                depth: .5,\n",
    "                zBias: 50\n",
    "               })\n",
    "        .text({font: 'Helvetica',\n",
    "               style: 'bold',\n",
    "               width:  16,\n",
    "               height: 5,\n",
    "               depth:  2,\n",
    "               expr: function (emit, i, j, k, time) {\n",
    "                   emit('(x(k), y(k), f(x(k), y(k)))');\n",
    "               },\n",
    "              })\n",
    "        .label({color: 0xFF9030,\n",
    "                snap: false,\n",
    "                outline: 2,\n",
    "                size: 24,\n",
    "                offset: [0, -32],\n",
    "                depth: .5,\n",
    "                zIndex: 1,\n",
    "               });\n",
    "    \n",
    "    \n",
    "})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
